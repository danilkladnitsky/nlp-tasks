{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework #4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import PorterStemmer\n",
    "\n",
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical, pad_sequences\n",
    "from keras.layers import Activation, Conv2D, Input, Embedding, Reshape, MaxPool2D, Concatenate, Flatten, Dropout, Dense, Conv1D\n",
    "from keras.layers import MaxPool1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 1234\n",
    "MAX_ROWS = 2000\n",
    "\n",
    "DATASET_TRUE_URL = \"https://raw.githubusercontent.com/danilkladnitsky/nlp-tasks/hw_4/hw_4/true.csv\"\n",
    "DATASET_FAKE_URL = \"https://raw.githubusercontent.com/danilkladnitsky/nlp-tasks/hw_4/hw_4/fake.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Вспомогательные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, filename):\n",
    "    already_downloaded = os.path.isfile(filename)\n",
    "\n",
    "    if (already_downloaded):\n",
    "        return True\n",
    "\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    open(filename, 'wb').write(r.content)\n",
    "\n",
    "\n",
    "def preprocess_text_context(content):\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', content)\n",
    "\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "\n",
    "    stops = stopwords.words('english')\n",
    "    porter = PorterStemmer()\n",
    "    for word in sentence.split():\n",
    "        if word in stops:\n",
    "            sentence = sentence.replace(word, '')\n",
    "        sentence = sentence.replace(word, porter.stem(word))\n",
    "    return sentence.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_file(DATASET_TRUE_URL, 'true.csv')\n",
    "download_file(DATASET_FAKE_URL, 'fake.csv')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "true_news_frame = pd.read_csv('true.csv')\n",
    "fake_news_frame = pd.read_csv('fake.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21417, 4)\n",
      "(23481, 4)\n"
     ]
    }
   ],
   "source": [
    "print(true_news_frame.shape)\n",
    "print(fake_news_frame.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_news_frame.reset_index(drop=True, inplace=True)\n",
    "fake_news_frame['is_fake'] = 1\n",
    "fake_news_frame.drop(columns=['subject', 'date'], inplace=True)\n",
    "fake_news_frame = fake_news_frame.head(MAX_ROWS)\n",
    "\n",
    "\n",
    "true_news_frame.reset_index(drop=True, inplace=True)\n",
    "true_news_frame['is_fake'] = 0\n",
    "true_news_frame.drop(columns=['subject', 'date'], inplace=True)\n",
    "true_news_frame = true_news_frame.head(MAX_ROWS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>is_fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3  FBI Russia probe helped by Australian diplomat...   \n",
       "4  Trump wants Postal Service to charge 'much mor...   \n",
       "\n",
       "                                                text  is_fake  \n",
       "0  WASHINGTON (Reuters) - The head of a conservat...        0  \n",
       "1  WASHINGTON (Reuters) - Transgender people will...        0  \n",
       "2  WASHINGTON (Reuters) - The special counsel inv...        0  \n",
       "3  WASHINGTON (Reuters) - Trump campaign adviser ...        0  \n",
       "4  SEATTLE/WASHINGTON (Reuters) - President Donal...        0  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_news_frame.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>is_fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text  is_fake  \n",
       "0  Donald Trump just couldn t wish all Americans ...        1  \n",
       "1  House Intelligence Committee Chairman Devin Nu...        1  \n",
       "2  On Friday, it was revealed that former Milwauk...        1  \n",
       "3  On Christmas day, Donald Trump announced that ...        1  \n",
       "4  Pope Francis used his annual Christmas Day mes...        1  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_news_frame.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Объединим данные в один фрейм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_frame = pd.concat([fake_news_frame, true_news_frame],\n",
    "                       ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(news_frame.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>is_fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>Trump rescinds Obama limits on transfer of mil...</td>\n",
       "      <td>WASHINGTON (Reuters) - U.S. President Donald T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>Lawmakers should OK relief for Harvey victims:...</td>\n",
       "      <td>WASHINGTON (Reuters) - U.S. House of Represent...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>Energy Secretary Perry cancels Kazakhstan visi...</td>\n",
       "      <td>ALMATY (Reuters) - United States Energy Secret...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>Trump's firm sought Moscow real estate deal du...</td>\n",
       "      <td>WASHINGTON (Reuters) - Donald Trump’s company ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>Trump renews threat to scrap NAFTA going into ...</td>\n",
       "      <td>WASHINGTON (Reuters) - U.S. President Donald T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "3995  Trump rescinds Obama limits on transfer of mil...   \n",
       "3996  Lawmakers should OK relief for Harvey victims:...   \n",
       "3997  Energy Secretary Perry cancels Kazakhstan visi...   \n",
       "3998  Trump's firm sought Moscow real estate deal du...   \n",
       "3999  Trump renews threat to scrap NAFTA going into ...   \n",
       "\n",
       "                                                   text  is_fake  \n",
       "3995  WASHINGTON (Reuters) - U.S. President Donald T...        0  \n",
       "3996  WASHINGTON (Reuters) - U.S. House of Represent...        0  \n",
       "3997  ALMATY (Reuters) - United States Energy Secret...        0  \n",
       "3998  WASHINGTON (Reuters) - Donald Trump’s company ...        0  \n",
       "3999  WASHINGTON (Reuters) - U.S. President Donald T...        0  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_frame.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Подготовим текстовые данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['nld', 'trump', 'wh', 'ri', 'hppi', 'new', 'yer', 'lev', 'th', 'sted', 'give', 'sh', 'enemi', 'rs', 't', 'dhonest', 'fke', 'news', 'di', 't', 'r', 'rely', 'show', 'str', 'one', 'job', 'countri', 'rpidli', 'grow', 'stronger', 'smrter', 'wnt', 'wh', 'friend', 'support', 'enemi', 'rs', 'even', 't', 'dhonest', 'fke', 'news', 'di', 'hppi', 'lthi', 'new', 'yer', 'presid', 'ngri', 'pnt', 'tweet', 'gre', 'yer', 'ric', 'countri', 'rpidli', 'grow', 'stronger', 'smrter', 'wnt', 'wh', 'friend', 'support', 'enemi', 'rs', 'even', 't', 'dhonest', 'fke', 'news', 'di', 'hppi', 'lthi', 'new', 'yer', 'gre', 'yer', 'ric', 'nld', 'trump', 'relnldtrump', 'decemr', 'trump', 'tweet', 'went', 'wn', 'b', 'wel', 'expect', 'wh', 'kd', 'presid', 'send', 'new', 'yer', 'greet', 'like', 't', 'despic', 'petti', 'fntil', 'gibrh', 'onli', 'trump', 'hi', 'lck', 'decenc', 'even', 'ow', 're', 't', 'gutter', 'long', 'eugh', 'wh', 't', 'ri', 'cizens', 'hppi', 'new', 'yer', 'bhop', 'tlrt', 'swn', 'tlrtswn', 'decemr', 'one', 'like', 'clv', 'clvswe', 'decemr', 'y', 'impech', 'would', 'mke', 'gre', 'yer', 'ric', 'l', 'ccept', 'reg', 'control', 'congress', 'mir', 'yver', 'miryver', 'decemr', 'r', 'yself', 'tlk', 'wn', 'clud', 'th', 'mni', 'peopl', 'th', 'der', 'whi', 't', 'ty', 'ln', 'sovl', 'lnsovl', 'decemr', 'use', 't', 'word', 'rs', 'new', 'yer', 'wh', 'mrlen', 'mrlen', 'decemr', 'sy', 'hppi', 'new', 'yer', 'koren', 'pot', 'korencrpenter', 'decemr', 're', 'trump', 'new', 'yer', 'eve', 'tweet', 'hppi', 'new', 'yer', 'cludg', 'mni', 'enemi', 'fought', 'lost', 'bdli', 'ty', 'n', 'kw', 'wh', 'love', 'nld', 'trump', 'relnldtrump', 'decemr', 't', 'thg', 'new', 'trump', 'en', 'g', 't', 'yer', 'trump', 'h', 'direct', 'ssges', 'enemi', 'rs', 'new', 'yer', 'eter', 'thnksgivg', 't', 'nniversri', 'pic', 'twter', 'com', 'fpe', 'kyp', 'dniel', 'dle', 'ddle', 'decemr', 'trump', 'holidy', 'tweet', 'clerli', 't', 'presidil', 'how', 'long', 'work', 'hmrk', 'e', 'comg', 'presid', 'steven', 'goode', 'sgoode', 'decemr', 'lwy', 'en', 'like', 't', 't', 'differ', 'th', 't', 'lt', 'yer', 'filter', 'h', 'en', 'brekg', 'wn', 'roy', 'schulz', 'thbthttt', 'decemr', 'prt', 'teeng', 'use', 't', 'term', 'rs', 'wendi', 'wendiwtles', 'decemr', 'fuckg', 'yer', 'old', 'kws', 'rydy', 'decemr', 'so', 't', 'peopl', 'vote', 't', 'hole', 'thkg', 'would', 'chnge', 'got', 'power', 'wrong', 'yer', 'old', 'n', 'n', 'chnge', 'w', 'yer', 'older', 'pho', 'andrew', 'burn', 'getti', 'imges'], ['hous', 'tellig', 'commte', 'chirmn', 'dev', 'nune', 'go', 'bd', 'dy', 'sumpt', 'like', 'mni', 'us', 'chrpr', 'steel', 'dossier', 'prompt', 'russi', 'vestig', 'lh', 'deprt', 'ic', 'fbi', 'order', 'protect', 'trump', 'hppen', 'dossier', 'strt', 'vestig', 'ccordg', 'document', 'obted', 'new', 'york', 'time', 'mer', 'trump', 'cmpign', 'dver', 'georg', 'ppdopoulo', 'drunk', 'we', 'br', 'wn', 'revel', 'kledg', 'russin', 'opposi', 'reserch', 'hillri', 'cln', 'p', 'ppdopoulo', 'n', 'covfef', 'boy', 'trump', 'h', 'dmtri', 'h', 'lleg', 'much', 'lrger', 'role', 'ne', 'dmng', 'beg', 'drunken', 'fool', 'we', 'br', 'cfee', 'boy', 'd', 'lp', 'rrng', 'new', 'york', 'meetg', 'trump', 'presid', 'bdel', 'fth', 'el', 'si', 'egypt', 'two', 'mths', 'bee', 'electi', 'it', 'kn', 'bee', 'mer', 'id', 'set', 'meetgs', 'wh', 'world', 'leder', 'trump', 'tem', 'trump', 'rn', 'wh', 'beg', 'mere', 'cfee', 'boy', 'in', 'my', 'ppdopoulo', 'revel', 'ustrlin', 'diplom', 'alexer', 'downer', 'russin', 'ficils', 'shoppg', 'round', 'possibl', 'dirt', 'n', 'democric', 'presidenti', 'nomee', 'hillri', 'cln', 'exctli', 'much', 'mr', 'ppdopoulo', 'sid', 'night', 'kensgn', 'we', 'room', 'wh', 'ustrlin', 'alexer', 'downer', 'uncler', 'report', 'stes', 'but', 'two', 'mths', 'ler', 'wn', 'lek', 'democric', 'emil', 'begn', 'pperg', 'le', 'ustrlin', 'ficils', 'psed', 'mi', 'b', 'mr', 'ppdopoulo', 'ir', 'mericn', 'counterprt', 'ccordg', 'four', 'current', 'mer', 'mericn', 'eign', 'ficils', 'wh', 'direct', 'kledg', 'ustrlins', 'role', 'ppdopoulo', 'pled', 'guilti', 'lyg', 'b', 'cooperg', 'wness', 'wh', 'specil', 'counsel', 'robert', 'mueller', 'tem', 'th', 'n', 'presid', 'it', 'bdly', 'script', 'rely', 'tv', 's', 'pho', 'w', 'mcnmee', 'getti', 'imges'], ['friday', 'veal', 'r', 'milwauke', 'srf', 'david', 'clark', 'csid', 'hold', 'secury', 'sectari', 'dald', 'trump', 'admtri', 'email', 'scdal', 'juary', 'brief', 'run', 'ple', 'clark', 'd', 'fellow', 'passeng', 'd', 'black', 'ler', 'detaed', 't', 'polic', 'as', 'whev', 'except', 'mayb', 'feelgs', 'hurt', 'clark', 'ssag', 't', 'polic', 'sp', 'black', 'depled', 'd', 'w', 'search', 'warrt', 'execut', 't', 'fbi', 'see', 't', 'exchges', 'clark', 'callg', 'fake', 'news', 'even', 'though', 'copi', 't', 'search', 'warrt', 't', 'ternet', 'untimid', 'lib', 'dia', 'tempt', 'sar', 'd', 'dcd', 'wh', 'tir', 'fake', 'new', 'pt', 'design', 'silenc', 't', 'r', 'srf', 'tet', 'ctue', 'poke', 'tm', 't', 'eye', 'wh', 'sharp', 'stick', 'd', 'bch', 'slap', 'tse', 'scum', 'bag', 'til', 'ty', 'get', 'tack', 'tter', 'peopl', 'th', 'tm', 'maga', 'untimid', 'lib', 'dia', 'tempt', 'sar', 'd', 'dcd', 'wh', 'tir', 'fake', 'new', 'pt', 'design', 'silenc', 'ctue', 'poke', 'tm', 't', 'eye', 'wh', 'sharp', 'stick', 'd', 'bch', 'slap', 'tse', 'scum', 'bag', 'til', 'ty', 'get', 'tack', 'tter', 'peopl', 'th', 'tm', 'maga', 'pic', 'twter', 'com', 'xtzw', 'pdu', 'david', 'clark', 'jr', 'srfclark', 'decemb', 'he', 'sp', 'bak', 'new', 'wn', 'ly', 'lib', 'dia', 'make', 'fake', 'new', 'sar', 't', 'antidot', 'go', 'right', 'tm', 'punch', 'tm', 't', 'se', 'make', 'tast', 'blood', 'nothg', 'get', 'bulli', 'like', 'ly', 'lib', 'dia', 'tenti', 'tter', 'th', 'give', 'tm', 'tast', 'tir', 'blood', 'neverbackd', 'pic', 'twter', 'com', 'ny', 'pshcr', 'david', 'clark', 'jr', 'srfclark', 'decemb', 't', 'ternet', 'call', 't', 'local', 'newspap', 'd', 'search', 'warrt', 'n', 'fake', 'd', 't', 'chose', 't', 'file', 'charg', 't', 'ti', 'ty', 'w', 'especi', 'ctue', 'lie', 'mths', 'deci', 't', 'charg', 'clark', 'email', 'search', 'warrt', 'file', 'http', 'co', 'zcc', 'wp', 'kehleblc', 'kehleblc', 'decemb', 'hope', 't', 'st', 't', 'villag', 'peopl', 'n', 'impliced', 'kirk', 'ketchum', 'kirkketchum', 'decemb', 'slaw', 'bake', 'potaes', 'fnch', 'fri', 'pic', 'twter', 'com', 'fwfxszxy', 'alt', 'immigri', 'alt', 'usc', 'decemb', 'pic', 'twter', 'com', 'ymbljfxu', 'pendulum', 'swger', 'pendulumswngr', 'decemb', 'call', 'polic', 'friend', 'std', 'wn', 'e', 'made', 'fun', 'h', 'chr', 'jacks', 'chrcjacks', 'decemb', 'is', 'wh', 't', 'master', 'pshop', 'h', 'seem', 'never', 'ti', 'thk', 't', 'steeli', 'lv', 'e', 'vible', 'eye', 'pic', 'twter', 'com', 'dwr', 'zezv', 'chr', 'mohney', 'chrmohney', 'decemb', 'a', 'dicg', 'wh', 'fgers', 'my', 'peopl', 'die', 'jail', 'thk', 'fgers', 'sht', 'dipsh', 'ike', 'barholtz', 'ikebarholtz', 'decemb', 'rl', 'ternet', 'ugh', 'guy', 'wh', 'fake', 'flair', 'pic', 'twter', 'com', 'ulcfddhkdi', 'kellmecrazi', 'kel', 'moface', 'decemb', 'edgi', 'buddi', 'mr', 'smh', 'mrssmh', 'decemb', 'is', 'bak', 'apple', 'aar', 'feltrrr', 'decemb', 'a', 'tryg', 'earn', 'still', 'levt', 'badg', 'circusrel', 'circusdw', 'decemb', 'make', 'su', 'hyd', 'drk', 'lot', 'r', 'it', 'rud', 'prs', 'c', 'deni', 'r', 'pr', 'ficials', 'rort', 'klc', 'rortklc', 'decemb', 'terril', 'thoma', 't', 'year', 'old', 'black', 'm', 'die', 'thirst', 'clark', 'milwauke', 'counti', 'jail', 'cell', 't', 'april', 'victim', 'homicid', 'thought', 'pot', 'it', 'c', 'peed', 'eugh', 'pho', 'spencer', 'plt', 'getti', 'imag'], ['chrtma', 'ay', 'al', 'trump', 'unc', 'woul', 'back', 'wk', 't', 'foow', 'ay', 'golf', 't', 'fourth', 'ay', 'row', 't', 'mer', 'reali', 's', 'star', 'blast', 'mer', 'presi', 'barack', 'obama', 'playg', 'golf', 'trump', 'track', 'pac', 't', 'numr', 'golf', 'game', 'h', 'preecess', 'play', 'tracker', 'trump', 'appear', 'trump', 'properti', 'roun', 'golf', 'clug', 'ay', 'th', 'pace', 'pass', 'obama', 'first', 'term', 'tal', 'juli', 'next', 'year', 'http', 'co', 'fg', 'vacxrtj', 'pic', 'twter', 'com', 'gemcjqtbh', 'philip', 'bump', 'pbump', 'decemr', 'th', 'make', 'wh', 'washgn', 'post', 'rept', 'ce', 'trump', 'bs', 'reay', 'ir', 'everythg', 'th', 'amtri', 'bizarr', 'af', 't', 'cog', 'ctae', 'refer', 'obama', 'golf', 'unlik', 'obama', 'wkg', 'fix', 't', 'problem', 't', 'golf', 'cours', 'h', 't', 'cog', 'e', 'crectli', 't', 'bs', 'al', 'trump', 'spent', 'sever', 'ay', 'row', 't', 'golf', 'cours', 'coe', 'serv', 't', 'foow', 'messag', 't', 'event', 'ternal', 'servr', 'err', 'http', 'co', 'zrwpymxrcz', 'pic', 'twter', 'com', 'wiqsqnnzw', 'chrpr', 'graham', 'cgraham', 'decemr', 'th', 'snippet', 'coe', 'appear', 'a', 'http', 'co', 'khw', 'alhb', 'page', 't', 'footer', 'say', 'pai', 't', 'rnc', 'pic', 'twter', 'com', 'oazt', 'chrpr', 'graham', 'cgraham', 'decemr', 'also', 'a', 'http', 'co', 'ayblgmk', 'as', 'otrs', 'e', 'th', 'threa', 'th', 'ir', 'coe', 'clear', 'woul', 'ever', 'actuay', 'play', 'ks', 'chrpr', 'graham', 'cgraham', 'decemr', 'after', 't', 'cog', 'cae', 't', 'refer', 'obama', 'elet', 't', 'golf', 'err', 'messag', 'en', 'remov', 't', 'trump', 'gop', 'bss', 'ty', 'also', 'fix', 't', 'javascript', 'vs', 'problem', 'sti', 'clear', 'wn', 'tse', 'messags', 'woul', 'actuay', 'play', 'sce', 't', 'actual', 'presum', 'page', 'plays', 'iffer', 'messag', 'pic', 'twter', 'com', 'q', 's', 'chrpr', 'graham', 'cgraham', 'decemr', 'th', 'suggest', 'somee', 'er', 'rnc', 't', 'trump', 'am', 'sensive', 'eugh', 'trump', 'golf', 'problem', 'make', 'th', 'sue', 'go', 'away', 'quickli', 'ce', 'peopl', 'ice', 'iea', 'much', 'love', 'see', 't', 'email', 'exchge', 'le', 'us', 're', 'chrpr', 'graham', 'cgraham', 'decemr', 't', 'coe', 'cke', 't', 'st', 'part', 'th', 'ty', 'usg', 't', 'assign', 'operar', 'mes', 'b', 'coe', 'wi', 'never', 'get', 'run', 'if', 'look', 'les', 'errcoe', 'wi', 'alway', 'tw', 'trsux', 'decemr', 'trump', 'coers', 'c', 'coe', 'noboy', 'surpre', 'tim', 'peters', 'timrpeters', 'decemr', 'al', 'trump', 'obsesse', 'wh', 'obama', 'h', 'name', 'even', 't', 'cog', 'h', 'bs', 'play', 'golf', 'aga', 'pho', 'joe', 'raele', 'getti', 'imag'], ['pope', 'frci', 'use', 'nual', 'chrtma', 'day', 'messag', 'rebuk', 'dald', 'trump', 'ut', 'even', 'menti', 'name', 'pope', 'deliv', 'messag', 'day', 'memr', 'un', 'nati', 'cdemn', 'trump', 'move', 'recogn', 'jerusalem', 'cap', 'rael', 'ptiff', 'pray', 'mday', 'peac', 'coext', 'two', 'state', 'wh', 'mutual', 'agre', 'ternatiy', 'recognd', 'bder', 'we', 'see', 'jesu', 'children', 'middl', 'et', 'ctue', 'suffer', 'growg', 'tens', 'rael', 'palest', 'frci', 'said', 't', 'festiv', 'day', 'let', 'us', 'k', 'ld', 'peac', 'jerusalem', 'holi', 'l', 'let', 'us', 'pray', 'resum', 'dialogu', 'may', 'prevail', 'parti', 'negoti', 'soluti', 'fy', 'reach', 'pope', 'went', 'plead', 'accept', 'refuge', 'en', 'ced', 'ir', 'home', 'sue', 'trump', 'ctues', 'fight', 'agt', 'frci', 'use', 'jesu', 're', 'w', 'place', 'n', 'alogy', 'day', 'wds', 'war', 'blowg', 'wld', 'dat', 'model', 'develop', 'ctues', 'produc', 'hum', 'societ', 'envirmental', 'decle', 'chrtma', 'ves', 'us', 'focu', 'sign', 'child', 'recogn', 'face', 'ltl', 'children', 'especiy', 'm', 'like', 'jesu', 're', 'place', 'n', 'said', 'jesu', 'kws', 'well', 'pa', 't', 'g', 'welcom', 'hard', 't', 'place', 'lay', 'e', 'ad', 'ad', 'may', 'arts', 't', 'close', 'y', 'home', 'bethlem', 'pope', 'said', 'mari', 'joseph', 'immigrts', 'struggl', 'fd', 'safe', 'place', 'stay', 'bethlem', 'y', 'leav', 'ir', 'peopl', 'ir', 'home', 'ir', 'l', 'frci', 'said', 't', 'w', 'comtable', 'ey', 'jney', 'young', 'coupl', 'child', 'at', 'art', 'y', 'full', 'hope', 'expectati', 'child', 'bn', 'yet', 'ir', 'step', 'weigd', 'uncertaties', 'dgers', 'attend', 'leav', 'ir', 'home', 'hd', 'so', 'my', 'footstep', 'hidden', 'footstep', 'joseph', 'mari', 'frci', 'said', 'sunday', 'we', 'see', 'track', 'entir', 'famili', 'ced', 'set', 'day', 'we', 'see', 'track', 'mill', 'perss', 't', 'choos', 'go', 'away', 'driven', 'ir', 'l', 'leav', 'hd', 'ir', 'dear', 'es', 'amen', 'pho', 'chrpr', 'furlg', 'getti', 'imag']]\n"
     ]
    }
   ],
   "source": [
    "plain_news_content = []\n",
    "\n",
    "for content in news_frame.text:\n",
    "    plain_news_content.append(preprocess_text_context(content).split())\n",
    "\n",
    "print(plain_news_content[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(plain_news_content, sample=500,\n",
    "                     window=3, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  13  201   28  126   32  749    9  744   50   85   24    1  111   12\n",
      "     7    6    1  116  520  159   16   20   50  166  974  749   26    4\n",
      "     1  448  749    9    4  358   98  440   34  729  749    2   56    1\n",
      "    48   34  642   11   24    4   13   31  374  445   13  370   93  387\n",
      "    40   63  687   98  440  838  220   37  374    5   83   13    9    4\n",
      "    98  577   22  135  132]\n",
      " [  15    7  569   28    1   17    1   12    1  362   78   35  124  288\n",
      "   416   61  133  933  810  170  590    1  281   38  589    2   46  156\n",
      "   145    2  544  462    5   94  156    5  184  170   17    3    1  716\n",
      "   937    2 1045    2    1 1210   41    5   12   83    4   17  292  441\n",
      "   504  334    9  357   24  505   37    4  554   14    9    4  774  289\n",
      "   577   22  377  135  132]]\n"
     ]
    }
   ],
   "source": [
    "token = Tokenizer(RANDOM_STATE)\n",
    "token.fit_on_texts(news_frame.text)\n",
    "text = token.texts_to_sequences(news_frame.text)\n",
    "text = pad_sequences(text, 75)\n",
    "print(text[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(news_frame.is_fake)\n",
    "y = to_categorical(y)\n",
    "y[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Реализовать классификацию двумя моделями: CNN, LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\firem\\AppData\\Local\\Temp\\ipykernel_4256\\3400662840.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  np.array(plain_news_content), y, test_size=0.2, stratify=y)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    np.array(plain_news_content), y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "unexpected end of input; is count incorrect or file otherwise damaged?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\ITMO\\MasterDegree\\nlp-tasks\\hw_4\\task.ipynb Cell 24\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/ITMO/MasterDegree/nlp-tasks/hw_4/task.ipynb#X43sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m w2v_vectors \u001b[39m=\u001b[39m w2v_model\u001b[39m.\u001b[39mwv\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/ITMO/MasterDegree/nlp-tasks/hw_4/task.ipynb#X43sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m w2v_vectors\u001b[39m.\u001b[39msave_word2vec_format(\u001b[39m'\u001b[39m\u001b[39mvectors.txt\u001b[39m\u001b[39m'\u001b[39m, binary\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/ITMO/MasterDegree/nlp-tasks/hw_4/task.ipynb#X43sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m keyed_vectors \u001b[39m=\u001b[39m gensim\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mKeyedVectors\u001b[39m.\u001b[39;49mload_word2vec_format(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/ITMO/MasterDegree/nlp-tasks/hw_4/task.ipynb#X43sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mvectors.txt\u001b[39;49m\u001b[39m'\u001b[39;49m, binary\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\ITMO\\MasterDegree\\nlp-tasks\\.venv\\lib\\site-packages\\gensim\\models\\keyedvectors.py:1719\u001b[0m, in \u001b[0;36mKeyedVectors.load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[0;32m   1672\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m   1673\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_word2vec_format\u001b[39m(\n\u001b[0;32m   1674\u001b[0m         \u001b[39mcls\u001b[39m, fname, fvocab\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, binary\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mutf8\u001b[39m\u001b[39m'\u001b[39m, unicode_errors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstrict\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1675\u001b[0m         limit\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, datatype\u001b[39m=\u001b[39mREAL, no_header\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   1676\u001b[0m     ):\n\u001b[0;32m   1677\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load KeyedVectors from a file produced by the original C word2vec-tool format.\u001b[39;00m\n\u001b[0;32m   1678\u001b[0m \n\u001b[0;32m   1679\u001b[0m \u001b[39m    Warnings\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1717\u001b[0m \n\u001b[0;32m   1718\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1719\u001b[0m     \u001b[39mreturn\u001b[39;00m _load_word2vec_format(\n\u001b[0;32m   1720\u001b[0m         \u001b[39mcls\u001b[39;49m, fname, fvocab\u001b[39m=\u001b[39;49mfvocab, binary\u001b[39m=\u001b[39;49mbinary, encoding\u001b[39m=\u001b[39;49mencoding, unicode_errors\u001b[39m=\u001b[39;49municode_errors,\n\u001b[0;32m   1721\u001b[0m         limit\u001b[39m=\u001b[39;49mlimit, datatype\u001b[39m=\u001b[39;49mdatatype, no_header\u001b[39m=\u001b[39;49mno_header,\n\u001b[0;32m   1722\u001b[0m     )\n",
      "File \u001b[1;32mc:\\ITMO\\MasterDegree\\nlp-tasks\\.venv\\lib\\site-packages\\gensim\\models\\keyedvectors.py:2065\u001b[0m, in \u001b[0;36m_load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[0;32m   2062\u001b[0m kv \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(vector_size, vocab_size, dtype\u001b[39m=\u001b[39mdatatype)\n\u001b[0;32m   2064\u001b[0m \u001b[39mif\u001b[39;00m binary:\n\u001b[1;32m-> 2065\u001b[0m     _word2vec_read_binary(\n\u001b[0;32m   2066\u001b[0m         fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, binary_chunk_size, encoding\n\u001b[0;32m   2067\u001b[0m     )\n\u001b[0;32m   2068\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2069\u001b[0m     _word2vec_read_text(fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, encoding)\n",
      "File \u001b[1;32mc:\\ITMO\\MasterDegree\\nlp-tasks\\.venv\\lib\\site-packages\\gensim\\models\\keyedvectors.py:1966\u001b[0m, in \u001b[0;36m_word2vec_read_binary\u001b[1;34m(fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, binary_chunk_size, encoding)\u001b[0m\n\u001b[0;32m   1964\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m   1965\u001b[0m \u001b[39mif\u001b[39;00m tot_processed_words \u001b[39m!=\u001b[39m vocab_size:\n\u001b[1;32m-> 1966\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEOFError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39munexpected end of input; is count incorrect or file otherwise damaged?\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mEOFError\u001b[0m: unexpected end of input; is count incorrect or file otherwise damaged?"
     ]
    }
   ],
   "source": [
    "# from gensim.test.utils import datapath\n",
    "\n",
    "# w2v_vectors = w2v_model.wv\n",
    "# w2v_vectors.save_word2vec_format('vectors.txt', binary=False)\n",
    "\n",
    "# keyed_vectors = gensim.models.KeyedVectors.load_word2vec_format(\n",
    "#     'vectors.txt', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The added layer must be an instance of class Layer. Received: layer=KeyedVectors<vector_size=100, 27 keys> of type <class 'gensim.models.keyedvectors.KeyedVectors'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\ITMO\\MasterDegree\\nlp-tasks\\hw_4\\task.ipynb Cell 25\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/ITMO/MasterDegree/nlp-tasks/hw_4/task.ipynb#X42sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m keras_model \u001b[39m=\u001b[39m Sequential()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/ITMO/MasterDegree/nlp-tasks/hw_4/task.ipynb#X42sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m keras_model\u001b[39m.\u001b[39;49madd(keyed_vectors)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/ITMO/MasterDegree/nlp-tasks/hw_4/task.ipynb#X42sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m keras_model\u001b[39m.\u001b[39madd(Dropout(\u001b[39m0.2\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/ITMO/MasterDegree/nlp-tasks/hw_4/task.ipynb#X42sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m keras_model\u001b[39m.\u001b[39madd(Conv1D(\u001b[39m50\u001b[39m, \u001b[39m3\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msame\u001b[39m\u001b[39m'\u001b[39m, strides\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\ITMO\\MasterDegree\\nlp-tasks\\.venv\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    206\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ITMO\\MasterDegree\\nlp-tasks\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\ITMO\\MasterDegree\\nlp-tasks\\.venv\\lib\\site-packages\\keras\\engine\\sequential.py:185\u001b[0m, in \u001b[0;36mSequential.add\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    183\u001b[0m         layer \u001b[39m=\u001b[39m functional\u001b[39m.\u001b[39mModuleWrapper(layer)\n\u001b[0;32m    184\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 185\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    186\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe added layer must be an instance of class Layer. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    187\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReceived: layer=\u001b[39m\u001b[39m{\u001b[39;00mlayer\u001b[39m}\u001b[39;00m\u001b[39m of type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(layer)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    188\u001b[0m     )\n\u001b[0;32m    190\u001b[0m tf_utils\u001b[39m.\u001b[39massert_no_legacy_layers([layer])\n\u001b[0;32m    191\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_layer_name_unique(layer):\n",
      "\u001b[1;31mTypeError\u001b[0m: The added layer must be an instance of class Layer. Received: layer=KeyedVectors<vector_size=100, 27 keys> of type <class 'gensim.models.keyedvectors.KeyedVectors'>."
     ]
    }
   ],
   "source": [
    "# keras_model = Sequential()\n",
    "\n",
    "# keras_model.add(keyed_vectors)\n",
    "\n",
    "# keras_model.add(Dropout(0.2))\n",
    "\n",
    "# keras_model.add(Conv1D(50, 3, activation='relu', padding='same', strides=1))\n",
    "# keras_model.add(Conv1D(50, 3, activation='relu', padding='same', strides=1))\n",
    "\n",
    "# keras_model.add(MaxPool1D())\n",
    "\n",
    "# keras_model.add(Dropout(0.2))\n",
    "\n",
    "# keras_model.add(Conv1D(100, 3, activation='relu', padding='same', strides=1))\n",
    "# keras_model.add(Conv1D(100, 3, activation='relu', padding='same', strides=1))\n",
    "\n",
    "# keras_model.add(MaxPool1D())\n",
    "\n",
    "# keras_model.add(Dropout(0.2))\n",
    "\n",
    "# keras_model.add(Conv1D(200, 3, activation='relu', padding='same', strides=1))\n",
    "# keras_model.add(Conv1D(200, 3, activation='relu', padding='same', strides=1))\n",
    "\n",
    "# keras_model.add(GlobalMaxPool1D())\n",
    "\n",
    "# keras_model.add(Dropout(0.2))\n",
    "\n",
    "# keras_model.add(Dense(200))\n",
    "\n",
    "# keras_model.add(Activation('relu'))\n",
    "\n",
    "# keras_model.add(Dropout(0.2))\n",
    "\n",
    "# keras_model.add(Dense(2))\n",
    "\n",
    "# keras_model.add(Activation('softmax'))\n",
    "\n",
    "# keras_model.compile(loss='binary_crossentropy',\n",
    "#                     metrics=['acc'], optimizer='adam')\n",
    "\n",
    "# keras_model.fit(x_train, y_train, batch_size=16, epochs=3,\n",
    "#                 validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сравнить качество обученных моделей"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
