{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets==2.14.6 in c:\\itmo\\masterdegree\\nlp-tasks\\.venv\\lib\\site-packages (from -r requirements.txt (line 1)) (2.14.6)\n",
      "Requirement already satisfied: transformers==4.35.0 in c:\\itmo\\masterdegree\\nlp-tasks\\.venv\\lib\\site-packages (from -r requirements.txt (line 2)) (4.35.0)\n",
      "Requirement already satisfied: torch==2.1.0 in c:\\itmo\\masterdegree\\nlp-tasks\\.venv\\lib\\site-packages (from -r requirements.txt (line 3)) (2.1.0)\n",
      "Requirement already satisfied: evaluate==0.4.1 in c:\\itmo\\masterdegree\\nlp-tasks\\.venv\\lib\\site-packages (from -r requirements.txt (line 4)) (0.4.1)\n",
      "Collecting huggingface_hub==0.18.0 (from -r requirements.txt (line 5))\n",
      "  Using cached huggingface_hub-0.18.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting ipywidgets==8.1.1 (from -r requirements.txt (line 6))\n",
      "  Downloading ipywidgets-8.1.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\itmo\\masterdegree\\nlp-tasks\\.venv\\lib\\site-packages (from datasets==2.14.6->-r requirements.txt (line 1)) (1.23.5)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\itmo\\masterdegree\\nlp-tasks\\.venv\\lib\\site-packages (from datasets==2.14.6->-r requirements.txt (line 1)) (14.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in c:\\itmo\\masterdegree\\nlp-tasks\\.venv\\lib\\site-packages (from datasets==2.14.6->-r requirements.txt (line 1)) (0.3.7)\n",
      "Requirement already satisfied: pandas in c:\\itmo\\masterdegree\\nlp-tasks\\.venv\\lib\\site-packages (from datasets==2.14.6->-r requirements.txt (line 1)) (2.1.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\itmo\\masterdegree\\nlp-tasks\\.venv\\lib\\site-packages (from datasets==2.14.6->-r requirements.txt (line 1)) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\itmo\\masterdegree\\nlp-tasks\\.venv\\lib\\site-packages (from datasets==2.14.6->-r requirements.txt (line 1)) (4.66.1)\n",
      "Requirement already satisfied: xxhash in c:\\itmo\\masterdegree\\nlp-tasks\\.venv\\lib\\site-packages (from datasets==2.14.6->-r requirements.txt (line 1)) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\itmo\\masterdegree\\nlp-tasks\\.venv\\lib\\site-packages (from datasets==2.14.6->-r requirements.txt (line 1)) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in c:\\itmo\\masterdegree\\nlp-tasks\\.venv\\lib\\site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.14.6->-r requirements.txt (line 1)) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in c:\\itmo\\masterdegree\\nlp-tasks\\.venv\\lib\\site-packages (from datasets==2.14.6->-r requirements.txt (line 1)) (3.8.6)\n",
      "Requirement already satisfied: packaging in c:\\itmo\\masterdegree\\nlp-tasks\\.venv\\lib\\site-packages (from datasets==2.14.6->-r requirements.txt (line 1)) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\itmo\\masterdegree\\nlp-tasks\\.venv\\lib\\site-packages (from datasets==2.14.6->-r requirements.txt (line 1)) (6.0.1)\n",
      "Requirement already satisfied: filelock in c:\\itmo\\masterdegree\\nlp-tasks\\.venv\\lib\\site-packages (from transformers==4.35.0->-r requirements.txt (line 2)) (3.13.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\itmo\\masterdegree\\nlp-tasks\\.venv\\lib\\site-packages (from transformers==4.35.0->-r requirements.txt (line 2)) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in c:\\itmo\\masterdegree\\nlp-tasks\\.venv\\lib\\site-packages (from transformers==4.35.0->-r requirements.txt (line 2)) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\itmo\\masterdegree\\nlp-tasks\\.venv\\lib\\site-packages (from transformers==4.35.0->-r requirements.txt (line 2)) (0.4.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\itmo\\masterdegree\\nlp-tasks\\.venv\\lib\\site-packages (from torch==2.1.0->-r requirements.txt (line 3)) (4.8.0)\n",
      "Requirement already satisfied: sympy in c:\\itmo\\masterdegree\\nlp-tasks\\.venv\\lib\\site-packages (from torch==2.1.0->-r requirements.txt (line 3)) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\itmo\\masterdegree\\nlp-tasks\\.venv\\lib\\site-packages (from torch==2.1.0->-r requirements.txt (line 3)) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\itmo\\masterdegree\\nlp-tasks\\.venv\\lib\\site-packages (from torch==2.1.0->-r requirements.txt (line 3)) (3.1.2)\n",
      "Requirement already satisfied: responses<0.19 in c:\\itmo\\masterdegree\\nlp-tasks\\.venv\\lib\\site-packages (from evaluate==0.4.1->-r requirements.txt (line 4)) (0.18.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\itmo\\masterdegree\\nlp-tasks\\.venv\\lib\\site-packages (from ipywidgets==8.1.1->-r requirements.txt (line 6)) (0.1.4)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\itmo\\masterdegree\\nlp-tasks\\.venv\\lib\\site-packages (from ipywidgets==8.1.1->-r requirements.txt (line 6)) (8.17.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\itmo\\masterdegree\\nlp-tasks\\.venv\\lib\\site-packages (from ipywidgets==8.1.1->-r requirements.txt (line 6)) (5.13.0)\n",
      "Collecting widgetsnbextension~=4.0.9 (from ipywidgets==8.1.1->-r requirements.txt (line 6))\n",
      "  Downloading widgetsnbextension-4.0.9-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.9 (from ipywidgets==8.1.1->-r requirements.txt (line 6))\n",
      "  Downloading jupyterlab_widgets-3.0.9-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\itmo\\masterdegree\\nlp-tasks\\.venv\\lib\\site-packages (from aiohttp->datasets==2.14.6->-r requirements.txt (line 1)) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\itmo\\masterdegree\\nlp-tasks\\.venv\\lib\\site-packages (from aiohttp->datasets==2.14.6->-r requirements.txt (line 1)) (3.3.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\itmo\\masterdegree\\nlp-tasks\\.venv\\lib\\site-packages (from aiohttp->datasets==2.14.6->-r requirements.txt (line 1)) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\itmo\\masterdegree\\nlp-tasks\\.venv\\lib\\site-packages (from aiohttp->datasets==2.14.6->-r requirements.txt (line 1)) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\itmo\\masterdegree\\nlp-tasks\\.venv\\lib\\site-packages (from aiohttp->datasets==2.14.6->-r requirements.txt (line 1)) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\itmo\\masterdegree\\nlp-tasks\\.venv\\lib\\site-packages (from aiohttp->datasets==2.14.6->-r requirements.txt (line 1)) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\itmo\\masterdegree\\nlp-tasks\\.venv\\lib\\site-packages (from aiohttp->datasets==2.14.6->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: decorator in c:\\itmo\\masterdegree\\nlp-tasks\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets==8.1.1->-r requirements.txt (line 6)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\itmo\\masterdegree\\nlp-tasks\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets==8.1.1->-r requirements.txt (line 6)) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\itmo\\masterdegree\\nlp-tasks\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets==8.1.1->-r requirements.txt (line 6)) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\itmo\\masterdegree\\nlp-tasks\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets==8.1.1->-r requirements.txt (line 6)) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\itmo\\masterdegree\\nlp-tasks\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets==8.1.1->-r requirements.txt (line 6)) (2.16.1)\n",
      "Requirement already satisfied: stack-data in c:\\itmo\\masterdegree\\nlp-tasks\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets==8.1.1->-r requirements.txt (line 6)) (0.6.3)\n",
      "Requirement already satisfied: exceptiongroup in c:\\itmo\\masterdegree\\nlp-tasks\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets==8.1.1->-r requirements.txt (line 6)) (1.1.3)\n",
      "Requirement already satisfied: colorama in c:\\itmo\\masterdegree\\nlp-tasks\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets==8.1.1->-r requirements.txt (line 6)) (0.4.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\itmo\\masterdegree\\nlp-tasks\\.venv\\lib\\site-packages (from requests>=2.19.0->datasets==2.14.6->-r requirements.txt (line 1)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\itmo\\masterdegree\\nlp-tasks\\.venv\\lib\\site-packages (from requests>=2.19.0->datasets==2.14.6->-r requirements.txt (line 1)) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\itmo\\masterdegree\\nlp-tasks\\.venv\\lib\\site-packages (from requests>=2.19.0->datasets==2.14.6->-r requirements.txt (line 1)) (2023.7.22)\n",
      "INFO: pip is looking at multiple versions of tokenizers to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tokenizers<0.15,>=0.14 (from transformers==4.35.0->-r requirements.txt (line 2))\n",
      "  Using cached tokenizers-0.14.0-cp39-none-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting evaluate==0.4.1 (from -r requirements.txt (line 4))\n",
      "  Using cached evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting transformers==4.35.0 (from -r requirements.txt (line 2))\n",
      "  Using cached transformers-4.35.0-py3-none-any.whl.metadata (123 kB)\n",
      "INFO: pip is still looking at multiple versions of tokenizers to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting datasets==2.14.6 (from -r requirements.txt (line 1))\n",
      "  Using cached datasets-2.14.6-py3-none-any.whl.metadata (19 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "\n",
      "The conflict is caused by:\n",
      "    The user requested huggingface_hub==0.18.0\n",
      "    datasets 2.14.6 depends on huggingface-hub<1.0.0 and >=0.14.0\n",
      "    transformers 4.35.0 depends on huggingface-hub<1.0 and >=0.16.4\n",
      "    evaluate 0.4.1 depends on huggingface-hub>=0.7.0\n",
      "    tokenizers 0.14.1 depends on huggingface_hub<0.18 and >=0.16.4\n",
      "    The user requested huggingface_hub==0.18.0\n",
      "    datasets 2.14.6 depends on huggingface-hub<1.0.0 and >=0.14.0\n",
      "    transformers 4.35.0 depends on huggingface-hub<1.0 and >=0.16.4\n",
      "    evaluate 0.4.1 depends on huggingface-hub>=0.7.0\n",
      "    tokenizers 0.14.0 depends on huggingface_hub<0.17 and >=0.16.4\n",
      "\n",
      "To fix this you could try to:\n",
      "1. loosen the range of package versions you've specified\n",
      "2. remove package versions to allow pip attempt to solve the dependency conflict\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Cannot install -r requirements.txt (line 1), -r requirements.txt (line 2), -r requirements.txt (line 4), huggingface_hub==0.18.0, tokenizers==0.14.1 and transformers because these package versions have conflicting dependencies.\n",
      "ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/abletobetable/distilbert-ru-qa\n",
    "selected_model = \"AlexKay/xlm-roberta-large-qa-multilingual-finedtuned-ru\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import evaluate\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sber_dataset = load_dataset(\"sberquad\")\n",
    "squad_dataset = load_dataset(\"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 87599\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 10570\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '56be8e613aeaaa14008c90d1', 'title': 'Super_Bowl_50', 'context': 'Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi\\'s Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.', 'question': 'What was the theme of Super Bowl 50?', 'answers': {'text': ['\"golden anniversary\"', 'gold-themed', '\"golden anniversary'], 'answer_start': [487, 521, 487]}}\n"
     ]
    }
   ],
   "source": [
    "print(squad_dataset[\"validation\"][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(selected_model)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(selected_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.is_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<s> When did the Scholastic Magazine of Notre dame begin publishing?</s></s> As at most other universities, Notre Dame's students run a number of news media outlets. The nine student-run outlets include three newspapers, both a radio and television station, and several magazines and journals. Begun as a one-page journal in September 1876, the Scholastic magazine is issued twice monthly and claims to be the oldest continuous collegiate publication in the United States. The other magazine, The Juggler, is released twice a year and focuses on student literature and artwork. The Dome yearbook is published annually. The newspapers have varying publication interests, with The Observer published daily and mainly reporting university and other news, and staffed by students from both Notre Dame and Saint Mary's College. Unlike Scholastic and The Dome, The Observer is an independent publication and does not have a faculty advisor or any editorial oversight from the University. In 1987, when some students believed that The Observer began to show a conservative bias, a liberal newspaper, Common Sense was published. Likewise, in 2003, when other students believed that the paper showed a liberal bias, the conservative paper Irish Rover went into production. Neither paper is published as often as The Observer; however, all three are distributed to all students. Finally, in Spring 2008 an undergraduate journal for political science research, Beyond Politics, made its debut.</s>\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = squad_dataset[\"train\"][5][\"context\"]\n",
    "question = squad_dataset[\"train\"][5][\"question\"]\n",
    "\n",
    "inputs = tokenizer(question, context)\n",
    "tokenizer.decode(inputs[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_validation_examples(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=100,\n",
    "        truncation=\"only_second\",\n",
    "        stride=50,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    example_ids = []\n",
    "\n",
    "    for i in range(len(inputs[\"input_ids\"])):\n",
    "        sample_idx = sample_map[i]\n",
    "        example_ids.append(examples[\"id\"][sample_idx])\n",
    "\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "        offset = inputs[\"offset_mapping\"][i]\n",
    "        inputs[\"offset_mapping\"][i] = [\n",
    "            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n",
    "        ]\n",
    "\n",
    "    inputs[\"example_id\"] = example_ids\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)okenizer_config.json: 100%|██████████| 29.0/29.0 [00:00<00:00, 9.64kB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 473/473 [00:00<00:00, 158kB/s]\n",
      "Downloading (…)solve/main/vocab.txt: 100%|██████████| 213k/213k [00:00<00:00, 649kB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 436k/436k [00:00<00:00, 1.20MB/s]\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 1428.59 examples/s]\n"
     ]
    }
   ],
   "source": [
    "eval_set = squad_dataset[\"validation\"].select(range(100))\n",
    "trained_checkpoint = \"distilbert-base-cased-distilled-squad\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(trained_checkpoint)\n",
    "eval_set = eval_set.map(\n",
    "    preprocess_validation_examples,\n",
    "    batched=True,\n",
    "    remove_columns=squad_dataset[\"validation\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(selected_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set_for_model = eval_set.remove_columns([\"example_id\", \"offset_mapping\"])\n",
    "eval_set_for_model.set_format(\"torch\")\n",
    "\n",
    "device = torch.device(\n",
    "    \"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "batch = {k: eval_set_for_model[k].to(device)\n",
    "         for k in eval_set_for_model.column_names}\n",
    "trained_model = AutoModelForQuestionAnswering.from_pretrained(selected_model).to(\n",
    "    device\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = trained_model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-7.450444 , -7.2323074, -7.8797503, ..., -7.69388  , -7.426134 ,\n",
       "         -7.668083 ],\n",
       "        [-7.2158074, -6.714641 , -7.325329 , ..., -6.4738503, -5.218007 ,\n",
       "         -6.730356 ],\n",
       "        [-7.2993956, -6.6172085, -7.563138 , ..., -6.7138453, -6.971804 ,\n",
       "         -7.43128  ],\n",
       "        ...,\n",
       "        [-7.176881 , -5.935554 , -7.494331 , ..., -7.122738 , -7.130123 ,\n",
       "         -7.0842752],\n",
       "        [-7.3994904, -6.1245375, -6.344665 , ..., -7.264229 , -7.142623 ,\n",
       "         -7.512552 ],\n",
       "        [-7.30225  , -6.3859806, -6.085725 , ..., -9.943708 , -9.944086 ,\n",
       "         -7.181176 ]], dtype=float32),\n",
       " array([[-5.7932386, -8.008629 , -6.6649036, ..., -5.9831257, -7.311994 ,\n",
       "         -5.797443 ],\n",
       "        [-5.440403 , -7.3044457, -5.5259466, ..., -4.038795 , -6.3687253,\n",
       "         -6.00023  ],\n",
       "        [-5.451812 , -7.659976 , -6.146906 , ..., -6.221962 , -7.5362883,\n",
       "         -5.7656736],\n",
       "        ...,\n",
       "        [-4.9833417, -8.051199 , -5.7997475, ..., -4.9630194, -4.974517 ,\n",
       "         -4.9098654],\n",
       "        [-5.324873 , -6.0594254, -6.940874 , ..., -5.792384 , -7.3420405,\n",
       "         -6.660776 ],\n",
       "        [-4.9137836, -5.973736 , -7.120179 , ..., -9.224583 , -9.2248955,\n",
       "         -4.80025  ]], dtype=float32))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_logits = outputs.start_logits.cpu().numpy()\n",
    "end_logits = outputs.end_logits.cpu().numpy()\n",
    "\n",
    "start_logits, end_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'56be4db0acb8001400a502ec': [0, 1, 2],\n",
       "             '56be4db0acb8001400a502ed': [3, 4, 5],\n",
       "             '56be4db0acb8001400a502ee': [6, 7, 8],\n",
       "             '56be4db0acb8001400a502ef': [9, 10, 11],\n",
       "             '56be4db0acb8001400a502f0': [12, 13, 14, 15],\n",
       "             '56be8e613aeaaa14008c90d1': [16, 17, 18],\n",
       "             '56be8e613aeaaa14008c90d2': [19, 20, 21],\n",
       "             '56be8e613aeaaa14008c90d3': [22, 23, 24],\n",
       "             '56bea9923aeaaa14008c91b9': [25, 26, 27],\n",
       "             '56bea9923aeaaa14008c91ba': [28, 29, 30],\n",
       "             '56bea9923aeaaa14008c91bb': [31, 32, 33],\n",
       "             '56beace93aeaaa14008c91df': [34, 35, 36],\n",
       "             '56beace93aeaaa14008c91e0': [37, 38, 39],\n",
       "             '56beace93aeaaa14008c91e1': [40, 41, 42],\n",
       "             '56beace93aeaaa14008c91e2': [43, 44, 45, 46],\n",
       "             '56beace93aeaaa14008c91e3': [47, 48, 49],\n",
       "             '56bf10f43aeaaa14008c94fd': [50, 51, 52, 53],\n",
       "             '56bf10f43aeaaa14008c94fe': [54, 55, 56],\n",
       "             '56bf10f43aeaaa14008c94ff': [57, 58, 59],\n",
       "             '56bf10f43aeaaa14008c9500': [60, 61, 62],\n",
       "             '56bf10f43aeaaa14008c9501': [63, 64, 65, 66],\n",
       "             '56d20362e7d4791d009025e8': [67, 68, 69],\n",
       "             '56d20362e7d4791d009025e9': [70, 71, 72],\n",
       "             '56d20362e7d4791d009025ea': [73, 74, 75],\n",
       "             '56d20362e7d4791d009025eb': [76, 77, 78],\n",
       "             '56d600e31c85041400946eae': [79, 80, 81],\n",
       "             '56d600e31c85041400946eb0': [82, 83, 84],\n",
       "             '56d600e31c85041400946eb1': [85, 86, 87],\n",
       "             '56d9895ddc89441400fdb50e': [88, 89, 90],\n",
       "             '56d9895ddc89441400fdb510': [91, 92, 93],\n",
       "             '56be4e1facb8001400a502f6': [94, 95, 96],\n",
       "             '56be4e1facb8001400a502f9': [97, 98, 99],\n",
       "             '56be4e1facb8001400a502fa': [100, 101],\n",
       "             '56beaa4a3aeaaa14008c91c2': [102, 103],\n",
       "             '56beaa4a3aeaaa14008c91c3': [104, 105, 106],\n",
       "             '56bead5a3aeaaa14008c91e9': [107, 108, 109],\n",
       "             '56bead5a3aeaaa14008c91ea': [110, 111, 112],\n",
       "             '56bead5a3aeaaa14008c91eb': [113, 114],\n",
       "             '56bead5a3aeaaa14008c91ec': [115, 116, 117],\n",
       "             '56bead5a3aeaaa14008c91ed': [118, 119],\n",
       "             '56bf159b3aeaaa14008c9507': [120, 121, 122],\n",
       "             '56bf159b3aeaaa14008c9508': [123, 124, 125],\n",
       "             '56bf159b3aeaaa14008c9509': [126, 127, 128, 129],\n",
       "             '56bf159b3aeaaa14008c950a': [130, 131, 132],\n",
       "             '56bf159b3aeaaa14008c950b': [133, 134, 135],\n",
       "             '56d2045de7d4791d009025f3': [136, 137],\n",
       "             '56d2045de7d4791d009025f4': [138, 139, 140],\n",
       "             '56d2045de7d4791d009025f5': [141, 142, 143],\n",
       "             '56d2045de7d4791d009025f6': [144, 145],\n",
       "             '56d6017d1c85041400946ebe': [146, 147, 148],\n",
       "             '56d6017d1c85041400946ec1': [149, 150, 151],\n",
       "             '56d6017d1c85041400946ec2': [152, 153, 154],\n",
       "             '56d98a59dc89441400fdb52a': [155, 156],\n",
       "             '56d98a59dc89441400fdb52b': [157, 158, 159],\n",
       "             '56d98a59dc89441400fdb52e': [160, 161],\n",
       "             '56be4eafacb8001400a50302': [162],\n",
       "             '56be4eafacb8001400a50303': [163],\n",
       "             '56be4eafacb8001400a50304': [164],\n",
       "             '56beab833aeaaa14008c91d2': [165],\n",
       "             '56beab833aeaaa14008c91d3': [166],\n",
       "             '56beab833aeaaa14008c91d4': [167],\n",
       "             '56beae423aeaaa14008c91f4': [168],\n",
       "             '56beae423aeaaa14008c91f5': [169],\n",
       "             '56beae423aeaaa14008c91f6': [170],\n",
       "             '56beae423aeaaa14008c91f7': [171],\n",
       "             '56bf17653aeaaa14008c9511': [172],\n",
       "             '56bf17653aeaaa14008c9513': [173],\n",
       "             '56bf17653aeaaa14008c9514': [174],\n",
       "             '56bf17653aeaaa14008c9515': [175],\n",
       "             '56d204ade7d4791d00902603': [176],\n",
       "             '56d204ade7d4791d00902604': [177],\n",
       "             '56d601e41c85041400946ece': [178],\n",
       "             '56d601e41c85041400946ecf': [179],\n",
       "             '56d601e41c85041400946ed0': [180],\n",
       "             '56d601e41c85041400946ed1': [181],\n",
       "             '56d601e41c85041400946ed2': [182],\n",
       "             '56d98b33dc89441400fdb53b': [183],\n",
       "             '56d98b33dc89441400fdb53c': [184],\n",
       "             '56d98b33dc89441400fdb53d': [185],\n",
       "             '56d98b33dc89441400fdb53e': [186],\n",
       "             '56be5333acb8001400a5030a': [187, 188],\n",
       "             '56be5333acb8001400a5030b': [189, 190],\n",
       "             '56be5333acb8001400a5030c': [191, 192],\n",
       "             '56be5333acb8001400a5030d': [193, 194],\n",
       "             '56be5333acb8001400a5030e': [195, 196],\n",
       "             '56beaf5e3aeaaa14008c91fd': [197, 198],\n",
       "             '56beaf5e3aeaaa14008c91fe': [199, 200],\n",
       "             '56beaf5e3aeaaa14008c91ff': [201, 202],\n",
       "             '56beaf5e3aeaaa14008c9200': [203, 204],\n",
       "             '56beaf5e3aeaaa14008c9201': [205, 206],\n",
       "             '56bf1ae93aeaaa14008c951b': [207, 208],\n",
       "             '56bf1ae93aeaaa14008c951c': [209, 210],\n",
       "             '56bf1ae93aeaaa14008c951e': [211, 212],\n",
       "             '56bf1ae93aeaaa14008c951f': [213, 214],\n",
       "             '56d2051ce7d4791d00902608': [215, 216],\n",
       "             '56d2051ce7d4791d00902609': [217, 218],\n",
       "             '56d2051ce7d4791d0090260a': [219, 220],\n",
       "             '56d2051ce7d4791d0090260b': [221, 222],\n",
       "             '56d602631c85041400946ed8': [223, 224],\n",
       "             '56d602631c85041400946eda': [225, 226]})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "example_to_features = collections.defaultdict(list)\n",
    "for idx, feature in enumerate(eval_set):\n",
    "    example_to_features[feature[\"example_id\"]].append(idx)\n",
    "\n",
    "\n",
    "example_to_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Используя набор данных Sberquad дообучить выбранную модель, оценить качество до и после дообучения"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
